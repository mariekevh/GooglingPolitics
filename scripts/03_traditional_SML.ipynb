{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLjq-VZG7ucE"
   },
   "source": [
    "## Traditional SML: Supervised Machine Learning models for PNR query detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1679400038194,
     "user": {
      "displayName": "Marieke",
      "userId": "07049110321640126395"
     },
     "user_tz": -60
    },
    "id": "O-mVX_5FHzSh",
    "outputId": "54216eea-0de3-445c-a483-58660dae047c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import joblib\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('dutch')\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "stemmer = SnowballStemmer('dutch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1679400041099,
     "user": {
      "displayName": "Marieke",
      "userId": "07049110321640126395"
     },
     "user_tz": -60
    },
    "id": "doaVpmtJIQxD"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train/test splits, cross validation, gridsearch\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "\n",
    "# class weights for NB\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# vectorizers\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# pipeline stuff\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "# Different models \n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC \n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, cohen_kappa_score, make_scorer, f1_score, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1679400043135,
     "user": {
      "displayName": "Marieke",
      "userId": "07049110321640126395"
     },
     "user_tz": -60
    },
    "id": "_QCb_0ooBrzM"
   },
   "outputs": [],
   "source": [
    "## preprocessing functions\n",
    "\n",
    "def transform_lowercase(x):\n",
    "    return x.lower()\n",
    "\n",
    "def remove_punctuation(x):\n",
    "    return re.sub(r'[^\\w\\s]|_', '', x)\n",
    "\n",
    "def remove_numbers(x):\n",
    "    return re.sub(r'\\d+', '', x)\n",
    "\n",
    "def remove_links(x):\n",
    "    return re.sub(r'http\\S+', '', x)\n",
    "\n",
    "def remove_linebreaks(x):\n",
    "    return x.replace('\\n', ' ').strip() # also remove double whitespace\n",
    "\n",
    "def remove_stopwords(x):\n",
    "    x = x.split(\" \")\n",
    "    x = \" \".join([w for w in x if (w not in stopwords)&(w!=\"\")]) # if not stop word or empty\n",
    "    return x\n",
    "\n",
    "def list_of_words(x):\n",
    "    return x.split(\" \")\n",
    "\n",
    "def tokenize(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    words_stemmed = [stemmer.stem(word) for word in words]\n",
    "    return words_stemmed\n",
    "\n",
    "def preprocess(x):\n",
    "    x = transform_lowercase(x)\n",
    "    x = remove_punctuation(x)\n",
    "    x = remove_numbers(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbzFH2TcKHWW"
   },
   "outputs": [],
   "source": [
    "def make_table(model_list, names, y_test, X_test):\n",
    "    '''\n",
    "    Takes list of classification reports as dicts as input, and outputs one table with only\n",
    "    '''\n",
    "    new = []\n",
    "    for model, name in zip(model_list, names):\n",
    "        dct = classification_report(y_test, model.predict(X_test), output_dict=True)\n",
    "        dct = dct['1']\n",
    "        dct.update({'model':name})\n",
    "        new.append(dct)\n",
    "    new=pd.DataFrame(new).set_index('model')\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZHvpOWpu78sO"
   },
   "outputs": [],
   "source": [
    "# identical test-train split to BERT\n",
    "X_train = np.load(\"data/train_test/X_train.npy\", allow_pickle=True)\n",
    "X_test = np.load(\"data/train_test/X_test.npy\", allow_pickle=True)\n",
    "y_train = np.load(\"data/train_test/y_train.npy\", allow_pickle=True)\n",
    "y_test = np.load(\"data/train_test/y_test.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1678436295321,
     "user": {
      "displayName": "Marieke",
      "userId": "07049110321640126395"
     },
     "user_tz": -60
    },
    "id": "uqX2G6UUdy7g",
    "outputId": "e81b0656-3897-4227-a35f-50e35c6ae00c"
   },
   "outputs": [],
   "source": [
    "# class balance in test and train data\n",
    "print('test data:', np.bincount(y_test))\n",
    "print('train data:', np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2XDZ7HdZuA1"
   },
   "outputs": [],
   "source": [
    "# Scorers\n",
    "f1_scorer = make_scorer(f1_score, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on relative importance of each class in the dataset (inverse frequency)\n",
    "class_weights1 = (1 - np.bincount(y_train)/len(y_train))\n",
    "class_weights1 = {0:class_weights1[0], 1:class_weights1[1]}\n",
    "class_weights1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4529L6gaF1C"
   },
   "source": [
    "# Logistic Regression with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6PIxujVhpy5l"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression with Tfidf\n",
    "pipeline_tfidf = Pipeline(steps=[('vectorizer', TfidfVectorizer()), ('classifier', LogisticRegression(solver='lbfgs'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YOyE7TTJaNm5"
   },
   "outputs": [],
   "source": [
    "grid = {'vectorizer__stop_words':[None, stopwords], # stopword removal\n",
    "        'vectorizer__max_df':[0.5, 1.0], # exclude terms in more than 50% or 100% of the docs\n",
    "        'vectorizer__min_df':[1, 5], # exclude terms in less than 1 or 5 documents.\n",
    "        'vectorizer__ngram_range':[(1,1), (1,2)], # consider unigrams, and both unigrams and bigrams\n",
    "        'vectorizer__preprocessor':[None, preprocess], # lowercase, delete punct and numbers\n",
    "        'vectorizer__analyzer':['word', tokenize], # word is default, tokenize is stemming\n",
    "        'classifier__class_weight':[None, 'balanced', class_weights1] # class weights\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zXuKOKb9bSfW"
   },
   "outputs": [],
   "source": [
    "search_LR_T = GridSearchCV(estimator=pipeline_tfidf, # first vectorizer, then classifier\n",
    "                      param_grid=grid, # test these paramaters\n",
    "                      scoring=f1_scorer, # use f1 scorer for label==1\n",
    "                      cv=5, # 5-fold cross validation\n",
    "                      n_jobs=-1, #use all cpus\n",
    "                      #verbose=2, # print output\n",
    "                      error_score='raise'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "gsu6w7NPfKz_",
    "outputId": "2c5b8f19-a825-45cd-db43-b1df9977ab16",
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_LR_T.fit(X_train, y_train)\n",
    "print(f'Using these hyperparameters {search_LR_T.best_params_}, we get the best performance.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "VXQPs4OrL-tC",
    "outputId": "e7e7a2a0-21e9-4885-aa06-30da9c81c20b"
   },
   "outputs": [],
   "source": [
    "LR_T = classification_report(y_test, search_LR_T.predict(X_test), output_dict=True)\n",
    "print(classification_report(y_test, search_LR_T.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "k1CRG18crAFV",
    "outputId": "d263be9f-5285-45ab-cf4c-89324d7fc146"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "joblib.dump(search_LR_T.best_estimator_, 'SML/LR_T.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrLImB4Jq1oz"
   },
   "source": [
    "# Logistic Regression with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "P1p4thlcfYM6"
   },
   "outputs": [],
   "source": [
    "pipeline_count = Pipeline(steps=[('vectorizer', CountVectorizer()), \n",
    "                           ('classifier', LogisticRegression(solver='lbfgs'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "CVmHI3yPfkQm"
   },
   "outputs": [],
   "source": [
    "search_LR_C = GridSearchCV(estimator=pipeline_count, # first vectorizer, then classifier\n",
    "                      param_grid=grid, # test these paramaters\n",
    "                      scoring=f1_scorer, # use f1 scorer for label==1\n",
    "                      cv=5, # 5-fold cross validation\n",
    "                      n_jobs=-1, #use all cpus\n",
    "                      #verbose=2, # print output\n",
    "                      error_score='raise'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "1ebJtYznfYPP",
    "outputId": "a0d61db7-ccb4-46b4-9eeb-63cbd1aaee9f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_LR_C.fit(X_train, y_train)\n",
    "print(f'Using these hyperparameters {search_LR_C.best_params_}, we get the best performance.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "CHqInjffMoiR",
    "outputId": "b96d1353-0e68-463d-e374-8605e32dddae"
   },
   "outputs": [],
   "source": [
    "LR_C = classification_report(y_test, search_LR_C.predict(X_test), output_dict=True)\n",
    "print(classification_report(y_test, search_LR_C.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "skxht09ouGRc",
    "outputId": "c4bf82dd-8ea1-4120-955d-3f7709a62711"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "joblib.dump(search_LR_C.best_estimator_, 'SML/LR_C.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVK8suq2fhtt"
   },
   "source": [
    "# Naive Bayes with Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1678376823292,
     "user": {
      "displayName": "Marieke",
      "userId": "07049110321640126395"
     },
     "user_tz": -60
    },
    "id": "vmRpAq7kfWxV",
    "outputId": "ea8c4d47-dc51-43a8-dca4-44f1e9fb4852"
   },
   "outputs": [],
   "source": [
    "pp = np.bincount(y_train)/len(y_train)\n",
    "print(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nuUPNtYCu0Rz"
   },
   "outputs": [],
   "source": [
    "pipeline_tfidf = Pipeline(steps=[('vectorizer', TfidfVectorizer()), \n",
    "                           ('classifier', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TL6ove_iuaIO"
   },
   "outputs": [],
   "source": [
    "gridNB = {'vectorizer__stop_words':[None, stopwords], # stopword removal\n",
    "        'vectorizer__max_df':[0.5, 1.0], # exclude terms in more than 50% or 100% of the docs\n",
    "        'vectorizer__min_df':[1, 5], # exclude terms in less than 1 or 5 documents.\n",
    "        'vectorizer__ngram_range':[(1,1), (1,2)], # consider unigrams, and both unigrams and bigrams\n",
    "        'vectorizer__preprocessor':[None, preprocess], # lowercase, delete punct and numbers\n",
    "        'vectorizer__analyzer':['word', tokenize], # word is default, tokenize is stemming\n",
    "        'classifier__class_prior':[None, pp]\n",
    "        #'classifier__class_weight':[None, 'balanced'] # class weights not a parameter in NB\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "jfaT1W2BM4Up"
   },
   "outputs": [],
   "source": [
    "search_NB_T = GridSearchCV(estimator=pipeline_tfidf, # first vectorizer, then classifier\n",
    "                      param_grid=gridNB, # test these paramaters\n",
    "                      scoring=f1_scorer, # use f1 scorer for label==1\n",
    "                      cv=5, # 5-fold cross validation\n",
    "                      n_jobs=-1, #use all cpus\n",
    "                      #verbose=2, # print output\n",
    "                      error_score='raise'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Wijjl4MdM4XI",
    "outputId": "d0599acf-1d9e-4474-bb6a-169e26d68d96",
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_NB_T.fit(X_train, y_train)\n",
    "print(f'Using these hyperparameters {search_NB_T.best_params_}, we get the best performance.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Htjw552JVn8W",
    "outputId": "4bbdf1bb-97be-4638-dfcd-cac06f204b5a"
   },
   "outputs": [],
   "source": [
    "NB_T = classification_report(y_test, search_NB_T.predict(X_test), output_dict=True)\n",
    "print(classification_report(y_test, search_NB_T.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "cGXkhw72YXqS",
    "outputId": "6738dee2-bfca-4787-f69c-bfd3e6fc6a08"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "joblib.dump(search_NB_T.best_estimator_, 'SML/NB_T.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cM-eMgMAuVvM"
   },
   "source": [
    "# Naive Bayes with Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1EzvAzhafYSr"
   },
   "outputs": [],
   "source": [
    "pipeline_count = Pipeline(steps=[('vectorizer', CountVectorizer()), \n",
    "                           ('classifier', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OzLHywbPus5e"
   },
   "outputs": [],
   "source": [
    "search_NB_C = GridSearchCV(estimator=pipeline_count, # first vectorizer, then classifier\n",
    "                      param_grid=gridNB, # test these paramaters\n",
    "                      scoring=f1_scorer, # use f1 scorer for label==1\n",
    "                      cv=5, # 5-fold cross validation\n",
    "                      n_jobs=-1, #use all cpus\n",
    "                      #verbose=2, # print output\n",
    "                      error_score='raise'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1182595,
     "status": "ok",
     "timestamp": 1678378012589,
     "user": {
      "displayName": "Marieke",
      "userId": "07049110321640126395"
     },
     "user_tz": -60
    },
    "id": "AV7m5VJ0Z87N",
    "outputId": "e01b64fc-87c4-4039-b96b-6a6c0fbfedde",
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_NB_C.fit(X_train, y_train)\n",
    "print(f'Using these hyperparameters {search_NB_C.best_params_}, we get the best performance.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1678378012590,
     "user": {
      "displayName": "Marieke",
      "userId": "07049110321640126395"
     },
     "user_tz": -60
    },
    "id": "qaPh8Ygsus2_",
    "outputId": "c6c0aa06-7b87-4d42-a335-bcf4ae7a4633"
   },
   "outputs": [],
   "source": [
    "NB_C = classification_report(y_test, search_NB_C.predict(X_test), output_dict=True)\n",
    "print(classification_report(y_test, search_NB_C.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1426,
     "status": "ok",
     "timestamp": 1678378014011,
     "user": {
      "displayName": "Marieke",
      "userId": "07049110321640126395"
     },
     "user_tz": -60
    },
    "id": "LPfTXf1oYn8M",
    "outputId": "88a38f16-92b9-40f0-9ea0-cf44f3fe6903"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "joblib.dump(search_NB_C.best_estimator_, 'SML/NB_C.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ja4IETn4nP2M"
   },
   "source": [
    "# LinearSVC with Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdjatqchnStM"
   },
   "outputs": [],
   "source": [
    "pipeline_tfidf = Pipeline(steps=[('vectorizer', TfidfVectorizer()), \n",
    "                           ('classifier', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqDPBmeenSlr"
   },
   "outputs": [],
   "source": [
    "# cutting some of the parameters based on the ones that are most plausible based on previous models (since otherwise it will take forever.)\n",
    "gridLSVC = {'vectorizer__stop_words':[None, stopwords], # stopword removal\n",
    "        'vectorizer__max_df':[0.5, 1.0], # exclude terms in more than 50% or 100% of the docs\n",
    "        'vectorizer__min_df':[1, 5], # exclude terms in less than 1 or 5 documents.\n",
    "        'vectorizer__ngram_range':[(1,1), (1,2)], # consider unigrams, and both unigrams and bigrams\n",
    "        'vectorizer__preprocessor':[None, preprocess], # lowercase, delete punct and numbers\n",
    "        'vectorizer__analyzer':['word', tokenize], # word is default, tokenize is stemming\n",
    "        'classifier__class_weight':[None, 'balanced', class_weights1], # balanced class weights\n",
    "        'classifier__C':[0.01, 1, 100] # regularization parameter\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9aJvR43TnSii"
   },
   "outputs": [],
   "source": [
    "search_LSVC_T = GridSearchCV(estimator=pipeline_tfidf, # first vectorizer, then classifier\n",
    "                      param_grid=gridLSVC, # test these paramaters\n",
    "                      scoring=f1_scorer, # use f1 scorer for label==1\n",
    "                      cv=5, # 5-fold cross validation\n",
    "                      n_jobs=-1, #use all cpus\n",
    "                      #verbose=10, # print output\n",
    "                      error_score='raise'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "executionInfo": {
     "elapsed": 4326949,
     "status": "ok",
     "timestamp": 1678440622261,
     "user": {
      "displayName": "Marieke",
      "userId": "07049110321640126395"
     },
     "user_tz": -60
    },
    "id": "nBOJ4amonsaT",
    "outputId": "99dc00c8-838b-4a0f-d674-b43f3764f78c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_LSVC_T.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1678440622261,
     "user": {
      "displayName": "Marieke",
      "userId": "07049110321640126395"
     },
     "user_tz": -60
    },
    "id": "rdlnoDV4nwbQ",
    "outputId": "3cc1e893-193a-436e-c6af-5d0912bfd635"
   },
   "outputs": [],
   "source": [
    "print(f'Using these hyperparameters {search_LSVC_T.best_params_}, we get the best performance.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1678440622567,
     "user": {
      "displayName": "Marieke",
      "userId": "07049110321640126395"
     },
     "user_tz": -60
    },
    "id": "oHTf_1PmnwY6",
    "outputId": "2f080ca7-7462-4be6-bc67-bb046aa1bf52"
   },
   "outputs": [],
   "source": [
    "LSVC_T = classification_report(y_test, search_LSVC_T.predict(X_test), output_dict=True)\n",
    "print(classification_report(y_test, search_LSVC_T.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 465,
     "status": "ok",
     "timestamp": 1678440623030,
     "user": {
      "displayName": "Marieke",
      "userId": "07049110321640126395"
     },
     "user_tz": -60
    },
    "id": "YEG8S6dOpI6W",
    "outputId": "aecfaf55-e593-4584-ba87-4813fa0f011a"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "joblib.dump(search_LSVC_T.best_estimator_, 'SML/LSVC_T.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldHLeYE_oGpK"
   },
   "source": [
    "# LinearSVC with Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K22-BBXgoGLZ"
   },
   "outputs": [],
   "source": [
    "pipeline_count = Pipeline(steps=[('vectorizer', CountVectorizer()), \n",
    "                           ('classifier', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUy1CpPyoGIz"
   },
   "outputs": [],
   "source": [
    "search_LSVC_C = GridSearchCV(estimator=pipeline_count, # first vectorizer, then classifier\n",
    "                      param_grid=gridLSVC, # test these paramaters\n",
    "                      scoring=f1_scorer, # use f1 scorer for label==1\n",
    "                      cv=5, # 5-fold cross validation\n",
    "                      n_jobs=-1, #use all cpus\n",
    "                      #verbose=10, # print output\n",
    "                      error_score='raise'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "executionInfo": {
     "elapsed": 4565963,
     "status": "ok",
     "timestamp": 1678445188990,
     "user": {
      "displayName": "Marieke",
      "userId": "07049110321640126395"
     },
     "user_tz": -60
    },
    "id": "dwG4M-_RoGGk",
    "outputId": "759e4672-d06f-41a3-8af3-f4976db4a5fc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_LSVC_C.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1678445188992,
     "user": {
      "displayName": "Marieke",
      "userId": "07049110321640126395"
     },
     "user_tz": -60
    },
    "id": "Qly8D30ooGEJ",
    "outputId": "a5129bbd-e37c-44cc-f109-354f8fc77ec6"
   },
   "outputs": [],
   "source": [
    "print(f'Using these hyperparameters {search_LSVC_C.best_params_}, we get the best performance.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1678445188993,
     "user": {
      "displayName": "Marieke",
      "userId": "07049110321640126395"
     },
     "user_tz": -60
    },
    "id": "ITi5V_gkoGBw",
    "outputId": "6cfbbe1a-6c41-45cf-fd73-4a9779076df6"
   },
   "outputs": [],
   "source": [
    "LSVC_C = classification_report(y_test, search_LSVC_C.predict(X_test), output_dict=True)\n",
    "print(classification_report(y_test, search_LSVC_C.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 844,
     "status": "ok",
     "timestamp": 1678445189826,
     "user": {
      "displayName": "Marieke",
      "userId": "07049110321640126395"
     },
     "user_tz": -60
    },
    "id": "8KMgzVOEpYUH",
    "outputId": "737be2ed-1c3e-4e70-cd73-3fcaccd57f83"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "joblib.dump(search_LSVC_C.best_estimator_, 'SML/LSVC_C.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pf3FEpxPp1o9"
   },
   "source": [
    "# Report after hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "executionInfo": {
     "elapsed": 324,
     "status": "error",
     "timestamp": 1679401455000,
     "user": {
      "displayName": "Marieke",
      "userId": "07049110321640126395"
     },
     "user_tz": -60
    },
    "id": "xNmlp4Kj9Rd9",
    "outputId": "14c567ef-75d1-44db-ba92-77ebaf76690d"
   },
   "outputs": [],
   "source": [
    "# load models\n",
    "LR_C = joblib.load('SML/LR_C.pkl')\n",
    "LR_T = joblib.load('SML/LR_T.pkl')\n",
    "NB_C = joblib.load('SML/NB_C.pkl')\n",
    "NB_T = joblib.load('SML/NB_T.pkl')\n",
    "LSVC_C = joblib.load('SML/LSVC_C.pkl')\n",
    "LSVC_T = joblib.load('SML/LSVC_T.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMU-vcyXprJc"
   },
   "outputs": [],
   "source": [
    "models = [LR_C, LR_T, NB_C, NB_T, LSVC_C, LSVC_T]\n",
    "names = [\"Logistic Regression with Count\", \"Logistic Regression with Tfidf\", \"Naive Bayes with Count\", \"Naive Bayes with Tfidf\", \"Linear Vector Classification with Count\", \"Linear Support Vector Classification with Tfidf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 640,
     "status": "ok",
     "timestamp": 1678446431272,
     "user": {
      "displayName": "Marieke",
      "userId": "07049110321640126395"
     },
     "user_tz": -60
    },
    "id": "ytqjErSPK9gR",
    "outputId": "ddf2a3a9-b7d4-44a3-f35a-0f2e403b8c91"
   },
   "outputs": [],
   "source": [
    "report = make_table(models, names, y_test, X_test)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HybidugOprHu"
   },
   "outputs": [],
   "source": [
    "report.round(2).to_latex('SML/report_SML.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, LSVC_T.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(classification_report(y_test, LSVC_T.predict(X_test), output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1925,
     "status": "ok",
     "timestamp": 1678446507899,
     "user": {
      "displayName": "Marieke",
      "userId": "07049110321640126395"
     },
     "user_tz": -60
    },
    "id": "reoH76U_qnWn",
    "outputId": "8ec7d5d6-a439-4c76-8534-36648c147f3e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# full report\n",
    "for model, name in zip(models, names):\n",
    "    print(name)\n",
    "    print(classification_report(y_test, model.predict(X_test)))\n",
    "    print('\\n')\n",
    "    cr = pd.DataFrame(classification_report(y_test, LSVC_T.predict(X_test), output_dict=True))\n",
    "    cr.round(2).to_latex(f'SML/results_{name}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNeuYB5moHXnpZhH5olEVfN",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
