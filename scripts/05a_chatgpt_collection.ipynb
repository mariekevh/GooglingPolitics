{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd423de4-740c-46fd-bb04-7d8f8d0975b7",
   "metadata": {},
   "source": [
    "# ChatGPT: Data collection via OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b32eb5-5b79-4f65-ae2a-22f5707e6901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b07d49c-f64d-4baf-a1fc-ac8a6b71aaa8",
   "metadata": {},
   "source": [
    "#### Prepare annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481e16c1-cf56-4d7f-a9ce-cae6034fd861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test-train split\n",
    "X_test = np.load(\"data/train_test/X_test.npy\", allow_pickle=True).tolist()\n",
    "y_test = np.load(\"data/train_test/y_test.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c24114-dd63-4313-b2d0-e6e4021e6836",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_c = [x.lower() for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e869f242-0369-4e30-a1e4-a54f1527d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({\"X_test\":X_test, \"y_test\":y_test, \"q_match\":X_test_c})\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125653ad-f99c-4bcf-8aa6-4394fbabcbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all annotations\n",
    "labels = pd.read_csv(\"data/annotations.csv\")\n",
    "#labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5df3ae7-6183-4ba2-8c4f-971d5b9d8beb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add date\n",
    "merged = pd.merge(test_df, labels[['q_match', 'short_date']], how='left')\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1453fc6-9418-48e2-92f6-914dd0d14154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text date column\n",
    "merged['short_date'] = pd.to_datetime(merged['short_date'])\n",
    "merged['date_strings'] = merged['short_date'].dt.strftime('%B %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ffa80-d68d-4ff8-af19-366cfc92641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## knowledge cut off chat gpt = Sep 2021\n",
    "cutoff_date = pd.to_datetime('2021-09-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ae5cee-e665-4072-bb25-8086c91ea84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['cutoff'] = np.where(merged['short_date']<= cutoff_date, 'before', 'after')\n",
    "merged.cutoff.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876ec5aa-eb11-495e-99e7-2d5669824049",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dates = merged[merged[\"cutoff\"]=='before']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c1186c-68d7-40e7-8993-602cae08d47a",
   "metadata": {},
   "source": [
    "## Predict using Chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c32d67d-41d3-4c2f-a4e7-0afadfa4f1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import openai\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca26499-6980-4f2e-b181-0a04042a8af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"INSERT_YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780fbf0c-0c7c-488b-a5bc-a834c4ee77da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds a delay to Completion API call\n",
    "def delayed_completion(delay_in_seconds: float = 1, **kwargs):\n",
    "    \"\"\"Delay a completion by a specified amount of time.\"\"\"\n",
    "\n",
    "    # Sleep for the delay\n",
    "    time.sleep(delay_in_seconds)\n",
    "\n",
    "    # Call the Completion API and return the result\n",
    "    return openai.ChatCompletion.create(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143d198d-e46d-4700-8017-cc801e3e21c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retries the API call with exponential backoff\n",
    "@retry(\n",
    "    wait=wait_random_exponential(min=1, max=60),\n",
    "    stop=stop_after_attempt(6),\n",
    "    retry_error_callback=lambda x: isinstance(x, openai.error.APIError),\n",
    ")\n",
    "def call_openai_api_with_backoff(prompt, delay):\n",
    "    response = delayed_completion(\n",
    "        delay_in_seconds=delay,\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0.2,\n",
    "        messages=[{'role':'user', 'content':prompt}]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c6b7d7-7c39-4491-9557-a7ee97a9a93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer extraction\n",
    "@retry(\n",
    "    wait=wait_random_exponential(min=1, max=60),\n",
    "    stop=stop_after_attempt(6),\n",
    "    retry_error_callback=lambda x: isinstance(x, openai.error.APIError),\n",
    ")\n",
    "def call_openai_api_with_backoff2(prompt, answer, delay):\n",
    "    followup = \"Therefore, the answer (yes or no) is\"\n",
    "    response = delayed_completion(\n",
    "        delay_in_seconds=delay,\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0.2,\n",
    "        messages=[{'role':'user', 'content':prompt},\n",
    "                  {'role':'assistant', 'content':answer},\n",
    "                 {'role':'user', 'content':followup}]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b29e5a-cc66-46e1-94fc-5b73efe3289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_labels_delayed(sq, date, delay, full_prompt):\n",
    "    # reasoning extraction\n",
    "    try:\n",
    "        response=call_openai_api_with_backoff(full_prompt, delay)\n",
    "        message = response['choices'][0]['message']['content']\n",
    "        finish_reason = response['choices'][0]['finish_reason']\n",
    "        \n",
    "    except:\n",
    "        print(\"First API request failed after multiple retries or timed out for search query:\", sq)\n",
    "        output = {'sq':sq,\n",
    "                 'date':date,\n",
    "                'message':None,\n",
    "                 'finish_reason':None,\n",
    "                 'message2':None,\n",
    "                 'finish_reason2':None}\n",
    "        return output\n",
    "        \n",
    "    if message: \n",
    "        # answer extraction\n",
    "        try:\n",
    "            response2 = call_openai_api_with_backoff2(full_prompt, message, delay)\n",
    "            message2 = response2['choices'][0]['message']['content']\n",
    "            finish_reason2 = response2['choices'][0]['finish_reason']\n",
    "\n",
    "            output = {'sq':sq,\n",
    "                     'date':date,\n",
    "                    'message':message,\n",
    "                     'finish_reason':finish_reason,\n",
    "                     'message2':message2,\n",
    "                     'finish_reason2':finish_reason2}\n",
    "            return output\n",
    "\n",
    "        except:\n",
    "            print(\"Second API request failed after multiple retries or timed out for search query:\", sq)\n",
    "            output = {'sq':sq,\n",
    "                     'date':date,\n",
    "                    'message':None,\n",
    "                     'finish_reason':None,\n",
    "                     'message2':None,\n",
    "                     'finish_reason2':None}\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaaccaf-f6bd-4133-b6ca-564220a0bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set rate limit per minute (max = 3000?)\n",
    "rate_limit_per_minute = 3000\n",
    "delay = 60.0 / rate_limit_per_minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1602de2d-d8fa-4965-b4c0-5bcd3c17c98e",
   "metadata": {},
   "source": [
    "## No dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb92250-632c-4b0c-bec7-22993fe86b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long definition, no date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352a7e2e-94de-4572-937c-4f51cd133ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_nodate = []\n",
    "for sq, date in tqdm(zip(merged.X_test.tolist(),merged.date_strings.tolist()), miniters=1):\n",
    "    # prompt\n",
    "    prompt = f'Is the search query \"{sq}\" political or news-related when searched in the Netherlands (yes or no)? Answer yes or no for whether the search query is political or news-related. Give your reasoning.'\n",
    "    explain = \"\\nPolitical or news-related search queries are defined as seeking information contributing to opinion formation on political and societal topics. This includes search queries about (international and national) political actors (e.g., political parties, politicians), elections, policy, political events (e.g., statements from political actors), news media (e.g., nos.nl, talk shows or programs that focus on societal themes (e.g., Op1, Boos, Zembla) (e.g., RTL Nieuws, NOS journaal vandaag) or figures in these media (e.g., Tim Hofman).\\nIt also includes search queries seeking out general information or news about societal themes (e.g., climate change, immigration, COVID-19, LGBT+, racism, crime, economy, war, etc.), but excludes those about practical information about these themes (e.g., checking pension benefits, getting vaccinated). In cases where it is unclear whether the search term is seeking general information or news about societal themes or practical information, follow the following rule: If the searcher's intention can be interpreted as interested in finding news or information about societal themes as well as practical, then answer yes (e.g., wait time for booster shot, easing of restrictions in France). If the search term can only be interpreted as seeking practical information, then answer no (e.g., vaccination line for Jansen, I want to get vaccinated).\\nA political or news-related search query can also be related to current events about political or societal themes (e.g., COVID-19, train strikes, The Voice schandal).\\nPolitical and news-related search queries are not about (natural) disasters (e.g., earthquakes, accidents), entertainment news (e.g., celebrities, fashion, gadgets, food), sports, culture (e.g., music radio, festivals), unless  when they concern policy related to these themes. A search term is never political or news-related when it concerns, for example, practical information (e.g., how long can you wear contact lenses, temperature tomorrow), shopping (e.g. IKEA Malm) or health.\"\n",
    "    full_prompt = prompt+explain\n",
    "    \n",
    "    # predict\n",
    "    output = gpt_labels_delayed(sq, date, delay, full_prompt)\n",
    "    # dump search term + prediction dict to document\n",
    "    with open('data/chatgpt_labels/long_nodate.json', 'a') as file: # appending to existing content\n",
    "        json.dump(output, file)\n",
    "        file.write('\\n')\n",
    "        \n",
    "    # append to notebook file\n",
    "    long_nodate.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c435969b-3bc3-4bb0-8e2f-23551b69557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(long_nodate).to_csv(\"data/chatgpt_labels/long_nodate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfab724-b05c-490b-a075-9bed889def6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf1a414-ad9b-4d82-81ce-48cc9d385dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# short prompt, no date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5556e0-78d0-4e08-84b4-569cc048e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_nodate = []\n",
    "for sq, date in tqdm(zip(merged.X_test.tolist(),merged.date_strings.tolist()), miniters=1):\n",
    "    \n",
    "    # prompt\n",
    "    prompt = f'Is the search query \"{sq}\" political or news-related when searched in the Netherlands (yes or no)? Political or news-related search queries are defined as seeking information contributing to opinion formation on political and societal topics. Give your reasoning.'\n",
    "    # predict\n",
    "    output = gpt_labels_delayed(sq, date, delay, prompt)\n",
    "    \n",
    "    # dump search term + prediction dict to document\n",
    "    with open('data/chatgpt_labels/short_nodate.json', 'a') as file: # appending to existing content\n",
    "        json.dump(output, file)\n",
    "        file.write('\\n')\n",
    "        \n",
    "    # append to notebook file\n",
    "    short_nodate.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd04582a-cf56-4ab1-8f20-131a9f0edbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(short_nodate).to_csv(\"data/chatgpt_labels/short_nodate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630c2bfb-fdaf-45bd-90be-31de7bc816cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca300bab-6142-41df-8f52-f094905eccec",
   "metadata": {},
   "source": [
    "## Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86a2577-6863-4be5-9b87-9a22e0d0575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long definition, with date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58c4af3-dc57-44ea-889e-5ded3e518b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_date = []\n",
    "for sq, date in tqdm(zip(merged_dates.X_test.tolist(),merged_dates.date_strings.tolist()), miniters=1):\n",
    "    # prompt\n",
    "    prompt_date = f'Is the search query \"{sq}\" political or news-related when searched in {date} in the Netherlands (yes or no)? Answer yes or no for whether the search query is political or news-related. Give your reasoning.'\n",
    "    explain = \"\\nPolitical or news-related search queries are defined as seeking information contributing to opinion formation on political and societal topics. This includes search queries about (international and national) political actors (e.g., political parties, politicians), elections, policy, political events (e.g., statements from political actors), news media (e.g., nos.nl, talk shows or programs that focus on societal themes (e.g., Op1, Boos, Zembla) (e.g., RTL Nieuws, NOS journaal vandaag) or figures in these media (e.g., Tim Hofman).\\nIt also includes search queries seeking out general information or news about societal themes (e.g., climate change, immigration, COVID-19, LGBT+, racism, crime, economy, war, etc.), but excludes those about practical information about these themes (e.g., checking pension benefits, getting vaccinated). In cases where it is unclear whether the search term is seeking general information or news about societal themes or practical information, follow the following rule: If the searcher's intention can be interpreted as interested in finding news or information about societal themes as well as practical, then answer yes (e.g., wait time for booster shot, easing of restrictions in France). If the search term can only be interpreted as seeking practical information, then answer no (e.g., vaccination line for Jansen, I want to get vaccinated).\\nA political or news-related search query can also be related to current events about political or societal themes (e.g., COVID-19, train strikes, The Voice schandal).\\nPolitical and news-related search queries are not about (natural) disasters (e.g., earthquakes, accidents), entertainment news (e.g., celebrities, fashion, gadgets, food), sports, culture (e.g., music radio, festivals), unless  when they concern policy related to these themes. A search term is never political or news-related when it concerns, for example, practical information (e.g., how long can you wear contact lenses, temperature tomorrow), shopping (e.g. IKEA Malm) or health.\"\n",
    "    full_prompt = prompt_date+explain\n",
    "    \n",
    "    # predict\n",
    "    output = gpt_labels_delayed(sq, date, delay, full_prompt)\n",
    "    \n",
    "    # dump search term + prediction dict to document\n",
    "    with open('data/chatgpt_labels/long_date.json', 'a') as file: # appending to existing content\n",
    "        json.dump(output, file)\n",
    "        file.write('\\n')\n",
    "        \n",
    "    # append to notebook file\n",
    "    long_date.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa42a8f2-deae-4a28-9104-76800d63e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(long_date).to_csv(\"data/chatgpt_labels/long_date.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ce5923-f7ac-4644-aed6-31dd6c963567",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d183e3c3-1c37-4cea-acec-87ff0533ada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# short definition, with date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bf8d11-cb6f-4596-9a7b-4ea033763013",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_date = []\n",
    "for sq, date in tqdm(zip(merged_dates.X_test.tolist(),merged_dates.date_strings.tolist()), miniters=1):\n",
    "    # prompt\n",
    "    prompt = f'Is the search query \"{sq}\" political or news-related when searched in {date} in the Netherlands (yes or no)? Political or news-related search queries are defined as seeking information contributing to opinion formation on political and societal topics. Give your reasoning.'\n",
    "    \n",
    "    # predict\n",
    "    output = gpt_labels_delayed(sq, date, delay, prompt)\n",
    "    \n",
    "    # dump search term + prediction dict to document\n",
    "    with open('data/chatgpt_labels/short_date.json', 'a') as file: # appending to existing content\n",
    "        json.dump(output, file)\n",
    "        file.write('\\n')\n",
    "        \n",
    "    # append to notebook file\n",
    "    short_date.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058ac51d-a6d4-43eb-93f9-6007a11e8b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626df442-ef0a-485b-b797-ab6fb096709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(short_date).to_csv(\"data/chatgpt_labels/short_date.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c6bbf3-def6-43fb-9073-0f3e94d05042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
